{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. NVIDIA GPU (cuStateVec FP64)\n",
      "   Elapsed time: 22.6124s\n",
      "   Result: -0.4658743243202536\n",
      "2. TensorNet (Full Contraction)\n",
      "   Elapsed time: 0.6061s\n",
      "   Result: -0.46587421381013505\n",
      "\n",
      "3. TensorNet MPS (Matrix Product State)\n",
      "   Elapsed time: 6.3675s\n",
      "   Result: -0.4658742138101219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# 2. 큐비트 수 및 파라미터 설정\n",
    "qubit_count = 30\n",
    "layer_count = 2\n",
    "\n",
    "total_params = layer_count * qubit_count\n",
    "initial_params = np.random.uniform(-np.pi, np.pi, total_params).tolist()\n",
    "\n",
    "@cudaq.kernel\n",
    "def mps_circuit(params: list[float]):\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    param_idx = 0\n",
    "\n",
    "    for l in range(layer_count):\n",
    "        for i in range(qubit_count):\n",
    "            ry(params[param_idx], qubits[i])\n",
    "            param_idx += 1\n",
    "        \n",
    "        for i in range(qubit_count - 1):\n",
    "            cx(qubits[i], qubits[i+1])\n",
    "\n",
    "print(\"1. NVIDIA GPU\")\n",
    "cudaq.set_target(\"nvidia\")\n",
    "s = time.time()\n",
    "for _ in range(30):\n",
    "    r = cudaq.observe(mps_circuit, cudaq.spin.z(0), initial_params).expectation()\n",
    "e = time.time()\n",
    "print(f\"   Elapsed time: {e - s:.4f}s\")\n",
    "print(f\"   Result: {r}\")\n",
    "\n",
    "# TensorNet Full Contraction 실행\n",
    "print(\"2. TensorNet (Full Contraction)\")\n",
    "cudaq.set_target(\"tensornet\")\n",
    "s = time.time()\n",
    "for _ in range(30):\n",
    "    r = cudaq.observe(mps_circuit, cudaq.spin.z(0), initial_params).expectation()\n",
    "e = time.time()\n",
    "print(f\"   Elapsed time: {e - s:.4f}s\")\n",
    "print(f\"   Result: {r}\\n\")\n",
    "\n",
    "# TensorNet MPS 실행 (더 메모리 효율적)\n",
    "print(\"3. TensorNet MPS (Matrix Product State)\")\n",
    "cudaq.set_target(\"tensornet-mps\")\n",
    "s = time.time()\n",
    "for _ in range(30):\n",
    "    r = cudaq.observe(mps_circuit, cudaq.spin.z(0), initial_params).expectation()\n",
    "e = time.time()\n",
    "print(f\"   Elapsed time: {e - s:.4f}s\")\n",
    "print(f\"   Result: {r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444eb644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Qubit: 60 | 2^60 = 1.0e+00 EB\n",
      "======================================================================\n",
      "FC: ✓ 0.0800s | Result: 0.528468\n",
      "MPS: ✓ 0.5157s | Result: 0.528468\n",
      "\n",
      "======================================================================\n",
      "Qubit: 70 | 2^70 = 1.0e+03 EB\n",
      "======================================================================\n",
      "FC: ✓ 0.0586s | Result: 0.746481\n",
      "MPS: ✓ 0.4618s | Result: 0.746481\n",
      "\n",
      "======================================================================\n",
      "Qubit: 80 | 2^80 = 1.0e+06 EB\n",
      "======================================================================\n",
      "FC: ✓ 0.0578s | Result: 0.405645\n",
      "MPS: ✓ 0.5138s | Result: 0.405645\n",
      "\n",
      "======================================================================\n",
      "Qubit: 90 | 2^90 = 1.1e+09 EB\n",
      "======================================================================\n",
      "FC: ✓ 0.0603s | Result: -0.393240\n",
      "MPS: ✓ 0.5759s | Result: -0.393240\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# 절대 한계 찾기\n",
    "for qubit_count in [60, 70, 80, 90]:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Qubit: {qubit_count} | 2^{qubit_count} = {2**qubit_count / (1024**6):.1e} EB\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    layer_count = 2\n",
    "    total_params = layer_count * qubit_count\n",
    "    initial_params = np.random.uniform(-np.pi, np.pi, total_params).tolist()\n",
    "\n",
    "    @cudaq.kernel\n",
    "    def mps_circuit(params: list[float]):\n",
    "        qubits = cudaq.qvector(qubit_count)\n",
    "        param_idx = 0\n",
    "\n",
    "        for l in range(layer_count):\n",
    "            for i in range(qubit_count):\n",
    "                ry(params[param_idx], qubits[i])\n",
    "                param_idx += 1\n",
    "            \n",
    "            for i in range(qubit_count - 1):\n",
    "                cx(qubits[i], qubits[i+1])\n",
    "\n",
    "    # TensorNet Full Contraction\n",
    "    print(\"FC: \", end=\"\", flush=True)\n",
    "    try:\n",
    "        cudaq.set_target(\"tensornet\")\n",
    "        s = time.time()\n",
    "        r = cudaq.observe(mps_circuit, cudaq.spin.z(0), initial_params).expectation()\n",
    "        e = time.time()\n",
    "        print(f\"✓ {e-s:.4f}s | Result: {r:.6f}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"✗ {type(ex).__name__}: OOM?\")\n",
    "\n",
    "    # TensorNet MPS\n",
    "    print(\"MPS: \", end=\"\", flush=True)\n",
    "    try:\n",
    "        cudaq.set_target(\"tensornet-mps\")\n",
    "        s = time.time()\n",
    "        r = cudaq.observe(mps_circuit, cudaq.spin.z(0), initial_params).expectation()\n",
    "        e = time.time()\n",
    "        print(f\"✓ {e-s:.4f}s | Result: {r:.6f}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"✗ {type(ex).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609aece5",
   "metadata": {},
   "source": [
    "# cuPauliProp 사용 방법\n",
    "\n",
    "**cuPauliProp (cuQuantum의 일부):**\n",
    "- Pauli operator propagation에 최적화\n",
    "- Clifford 회로 시뮬레이션에 매우 효율적\n",
    "- **C++ 직접 사용 필요**\n",
    "\n",
    "**CUDA-Q와의 차이:**\n",
    "- CUDA-Q: High-level Python API, 범용 시뮬레이션\n",
    "- cuPauliProp: Low-level C++ API, Pauli 특화\n",
    "\n",
    "**생성된 파일:**\n",
    "1. `pauli_prop_example.cpp` - cuPauliProp 사용 예제\n",
    "2. `compile_pauli_prop.sh` - 컴파일 스크립트\n",
    "\n",
    "**컴파일 및 실행:**\n",
    "```bash\n",
    "chmod +x compile_pauli_prop.sh\n",
    "./compile_pauli_prop.sh\n",
    "./pauli_prop_example\n",
    "```\n",
    "\n",
    "**주요 기능:**\n",
    "- Pauli 문자열 표현 및 전파\n",
    "- Clifford gate (H, S, CNOT 등) 적용\n",
    "- Pauli rotation gate\n",
    "- 노이즈 채널 시뮬레이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0af2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd6257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c13cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA-Q version: CUDA-Q Version 0.12.0 (https://github.com/NVIDIA/cuda-quantum 6adf92bcda4df7465e4fe82f1c8f782ae69d8bd2)\n",
      "\n",
      "Available targets:\n",
      "  - Target tensornet-mps\n",
      "\tsimulator=tensornet_mps\n",
      "\tplatform=default\n",
      "\tdescription=cutensornet simulator backend target based on matrix product state representation\n",
      "\tprecision=fp64\n",
      "Supported Arguments:\n",
      "  - option (Specify the target options as a comma-separated list.\n",
      "Supported options are 'fp32', 'fp64')\n",
      "\n",
      "  - Target stim\n",
      "\tsimulator=stim\n",
      "\tplatform=default\n",
      "\tdescription=Stim-based CPU-only backend target\n",
      "\tprecision=fp64\n",
      "\n",
      "  - Target quera\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for QuEra.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - machine (Specify the QuEra QPU.)\n",
      "  - default_bucket (Specify a default S3 bucket for QuEra results.)\n",
      "\n",
      "  - Target quantum_machines\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for Quantum Machines.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - url (Specify Quantum Machine base server url.)\n",
      "  - executor (Specify the executor to run. Default is mock)\n",
      "  - api_key (An API key to access the Qoperator server)\n",
      "\n",
      "  - Target pasqal\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for pasqal.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - machine (Specify the Pasqal machine to target, FRESNEL to target QPU and EMU_MPS to run on a MPS emulator.)\n",
      "\n",
      "  - Target orca\n",
      "\tsimulator=qpp\n",
      "\tplatform=mqpu\n",
      "\tdescription=CUDA-Q target for Orca.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - url (Specify URL.)\n",
      "  - machine (Specify the Orca QPU.)\n",
      "\n",
      "  - Target nvqc\n",
      "\tsimulator=qpp\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVQC Target provides access to simulated QPU services hosted on the NVIDIA Quantum Cloud.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - backend (Specify the remote simulator backend.)\n",
      "  - nqpus (Specify the number of virtual NVQC QPUs.)\n",
      "  - ngpus (Specify the number of GPUs required.)\n",
      "  - function-id (Specify the NVQC function Id.)\n",
      "  - function-version-id (Specify the NVQC function version Id.)\n",
      "  - api-key (Specify NVQC API key.)\n",
      "\n",
      "  - Target nvidia-mqpu-fp64\n",
      "\tsimulator=cusvsim_fp64\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU FP64 Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP64.\n",
      "\tprecision=fp64\n",
      "\n",
      "  - Target tensornet\n",
      "\tsimulator=tensornet\n",
      "\tplatform=default\n",
      "\tdescription=cutensornet simulator backend target based on full tensor network contraction\n",
      "\tprecision=fp64\n",
      "Supported Arguments:\n",
      "  - option (Specify the target options as a comma-separated list.\n",
      "Supported options are 'fp32', 'fp64')\n",
      "\n",
      "  - Target braket\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for Amazon Braket.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - machine (Specify the Amazon Braket QPU.)\n",
      "  - default_bucket (Specify a default S3 bucket for Amazon Braket results.)\n",
      "  - polling_interval_ms (Specify the polling interval (in milliseconds) for checking task completion status on Amazon Braket.)\n",
      "  - noise-model (Specify the noise model for simulation.)\n",
      "\n",
      "  - Target oqc\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for Oxford Quantum Circuits.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - email (Specify user's email address.)\n",
      "  - url (Specify the URL.)\n",
      "  - machine (Specify QPU.)\n",
      "\n",
      "  - Target ionq\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for IonQ.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - machine (Specify the IonQ QPU.)\n",
      "  - noise-model (Specify the noise model for simulation.)\n",
      "  - debias (Specify debiasing.)\n",
      "  - sharpen (Specify sharpening.)\n",
      "\n",
      "  - Target density-matrix-cpu\n",
      "\tsimulator=dm\n",
      "\tplatform=default\n",
      "\tdescription=The Density Matrix CPU Target provides a simulated QPU via OpenMP-enabled, CPU-only density matrix emulation.\n",
      "\tprecision=fp64\n",
      "\n",
      "  - Target fermioniq\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for Fermioniq.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - remote-config (Specify the Fermioniq Remote Configuration.)\n",
      "  - project-id (Specify the project.)\n",
      "  - bond-dim (Specify bond-dimension. Applies to all circuits.)\n",
      "\n",
      "  - Target iqm\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for IQM.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - server-url (Specify URL.)\n",
      "  - machine (Specify the IQM QPU.)\n",
      "\n",
      "  - Target quantinuum\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for Quantinuum.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - url (Specify the URL.)\n",
      "  - machine (Specify QPU.)\n",
      "\n",
      "  - Target dynamics\n",
      "\tsimulator=dynamics\n",
      "\tplatform=mqpu\n",
      "\tdescription=Dynamics simulation backend\n",
      "\tprecision=fp32\n",
      "\n",
      "  - Target nvidia-mgpu\n",
      "\tsimulator=nvidia_mgpu\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA Target provides a simulated QPU via multi-node multi-GPU cuStateVec integration.\n",
      "\tprecision=fp64\n",
      "\n",
      "  - Target remote-mqpu\n",
      "\tsimulator=qpp\n",
      "\tplatform=mqpu\n",
      "\tdescription=The remote-mqpu target provides locally-hosted CUDA-Q simulator runtime services.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - backend (Specify the remote simulator backend.)\n",
      "  - url (Specify the URL of the server.)\n",
      "  - auto-launch (Specify the number of server instances to be launched and shut down automatically.)\n",
      "\n",
      "  - Target qpp-cpu\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=QPP-based CPU-only backend target\n",
      "\tprecision=fp64\n",
      "\n",
      "  - Target nvidia-mqpu\n",
      "\tsimulator=cusvsim_fp32\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP32. This target enables asynchronous parallel execution of quantum kernel tasks.\n",
      "\tprecision=fp32\n",
      "\n",
      "  - Target nvidia\n",
      "\tsimulator=cusvsim_fp32\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA Target provides a simulated QPU via cuStateVec (state-vector simulation) integration.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - option (Specify the target options as a comma-separated list.\n",
      "Supported options are 'fp32', 'fp64', 'mgpu', 'mqpu'.\n",
      "For example, the 'fp32,mgpu' option combination will activate multi-GPU distribution with single-precision. Not all option combinations are supported.)\n",
      "\n",
      "  - Target nvidia-fp64\n",
      "\tsimulator=cusvsim_fp64\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA FP64 Target provides a simulated QPU via single-GPU cuStateVec integration on FP64 types.\n",
      "\tprecision=fp64\n",
      "\n",
      "  - Target orca-photonics\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=Photonics simulator\n",
      "\tprecision=fp32\n",
      "\n",
      "  - Target opt-test\n",
      "\tsimulator=cusvsim_fp32\n",
      "\tplatform=default\n",
      "\tdescription=Compiler Optimization Test Target\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - option (Specify the target options as a comma-separated list.\n",
      "Supported options are 'dep-analysis, 'fp32', 'fp64', 'qpp'.\n",
      "For example, the 'dep-analysis,fp32' option combination will activate single-precision simulation with the dep-analysis passes. Not all option combinations are supported.)\n",
      "\n",
      "  - Target anyon\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for Anyon.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - url (Specify the URL.)\n",
      "  - machine (Specify QPU.)\n",
      "\n",
      "  - Target infleqtion\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=CUDA-Q target for Infleqtion.\n",
      "\tprecision=fp32\n",
      "Supported Arguments:\n",
      "  - machine (Specify the Infleqtion backend to run on.)\n",
      "  - method (Specify the circuit execution type, either: dry-run (ideal simulation) or noise-sim (noisy-simulation).)\n",
      "\n",
      "  - Target nvidia-mqpu-mps\n",
      "\tsimulator=tensornet_mps\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuTensorNet MPS. This target enables asynchronous parallel execution of quantum kernel tasks.\n",
      "\tprecision=fp64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CUDA-Q 버전 확인\n",
    "print(\"CUDA-Q version:\", cudaq.__version__)\n",
    "\n",
    "# 사용 가능한 백엔드 확인\n",
    "print(\"\\nAvailable targets:\")\n",
    "targets = cudaq.get_targets()\n",
    "for target in targets:\n",
    "    print(f\"  - {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c7c0a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current target: Target tensornet\n",
      "\tsimulator=tensornet\n",
      "\tplatform=default\n",
      "\tdescription=cutensornet simulator backend target based on full tensor network contraction\n",
      "\tprecision=fp64\n",
      "Supported Arguments:\n",
      "  - option (Specify the target options as a comma-separated list.\n",
      "Supported options are 'fp32', 'fp64')\n",
      "\n",
      "Target description: cutensornet simulator backend target based on full tensor network contraction\n",
      "\n",
      "Environment variables related to tensornet/cuQuantum:\n",
      "  CUDAQ_DYNLIBS=/home/ubuntu/miniconda3/envs/lqgan/lib/python3.11/site-packages/cuquantum/lib/libcustatevec.so.1:/home/ubuntu/miniconda3/envs/lqgan/lib/python3.11/site-packages/cuquantum/lib/libcutensornet.so.2:/home/ubuntu/miniconda3/envs/lqgan/lib/python3.11/site-packages/cuquantum/lib/libcudensitymat.so.0:/home/ubuntu/miniconda3/envs/lqgan/lib/python3.11/site-packages/cutensor/lib/libcutensor.so.2:/home/ubuntu/miniconda3/envs/lqgan/lib/python3.11/site-packages/nvidia/cuda_runtime/lib/libcudart.so.12:/home/ubuntu/miniconda3/envs/lqgan/lib/python3.11/site-packages/nvidia/curand/lib/libcurand.so.10:/home/ubuntu/miniconda3/envs/lqgan/lib/python3.11/site-packages/nvidia/cuda_nvrtc/lib/libnvrtc.so.12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tensornet 백엔드의 설정 확인\n",
    "cudaq.set_target(\"tensornet\")\n",
    "target_info = cudaq.get_target()\n",
    "print(f\"\\nCurrent target: {target_info}\")\n",
    "print(f\"Target description: {target_info.description if hasattr(target_info, 'description') else 'N/A'}\")\n",
    "\n",
    "# tensornet 관련 환경변수 확인\n",
    "import os\n",
    "print(\"\\nEnvironment variables related to tensornet/cuQuantum:\")\n",
    "for key, value in os.environ.items():\n",
    "    if 'TENSOR' in key.upper() or 'CUDA' in key.upper() or 'CUTENSOR' in key.upper():\n",
    "        print(f\"  {key}={value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f8df87a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "requested size is too big",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m s = time.time()\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m30\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     r = \u001b[43mcudaq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmps_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcudaq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mz\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m)\u001b[49m.expectation()\n\u001b[32m     37\u001b[39m e = time.time()\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mElapsed time for 30 executions:\u001b[39m\u001b[33m\"\u001b[39m, e - s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lqgan/lib/python3.11/site-packages/cudaq/runtime/observe.py:128\u001b[39m, in \u001b[36mobserve\u001b[39m\u001b[34m(kernel, spin_operator, shots_count, noise_model, num_trajectories, execution, *args)\u001b[39m\n\u001b[32m    126\u001b[39m     ctx.numberTrajectories = num_trajectories\n\u001b[32m    127\u001b[39m cudaq_runtime.setExecutionContext(ctx)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m res = ctx.result\n\u001b[32m    130\u001b[39m cudaq_runtime.resetExecutionContext()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/lqgan/lib/python3.11/site-packages/cudaq/kernel/kernel_decorator.py:522\u001b[39m, in \u001b[36mPyKernelDecorator.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    519\u001b[39m         processedArgs.append(arg)\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returnType == \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     \u001b[43mcudaq_runtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyAltLaunchKernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mprocessedArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mcallable_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallableNames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    527\u001b[39m     result = cudaq_runtime.pyAltLaunchKernelR(\n\u001b[32m    528\u001b[39m         \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    529\u001b[39m         \u001b[38;5;28mself\u001b[39m.module,\n\u001b[32m    530\u001b[39m         mlirTypeFromPyType(\u001b[38;5;28mself\u001b[39m.returnType, \u001b[38;5;28mself\u001b[39m.module.context),\n\u001b[32m    531\u001b[39m         *processedArgs,\n\u001b[32m    532\u001b[39m         callable_names=callableNames)\n",
      "\u001b[31mRuntimeError\u001b[39m: requested size is too big"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "# 1. 텐서 네트워크 백엔드 설정 (MPS 시뮬레이션 최적화)\n",
    "cudaq.set_target(\"nvidia\")\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def mps_circuit(params: list[float]):\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    param_idx = 0\n",
    "\n",
    "    # 레이어 반복\n",
    "    for l in range(layer_count):\n",
    "        # (1) Single-qubit Rotation Layer\n",
    "        for i in range(qubit_count):\n",
    "            ry(params[param_idx], qubits[i])\n",
    "            param_idx += 1\n",
    "        \n",
    "        # (2) Entanglement Layer (Nearest-Neighbor / MPS Style)\n",
    "        for i in range(qubit_count - 1):\n",
    "            cx(qubits[i], qubits[i+1])\n",
    "\n",
    "# 4. 임의의 파라미터 생성 및 실행\n",
    "# 필요한 파라미터 수: 레이어 수 * 큐비트 수\n",
    "\n",
    "\n",
    "# 회로 실행 및 결과 확인\n",
    "s = time.time()\n",
    "for _ in range(30):\n",
    "    r = cudaq.observe(mps_circuit, cudaq.spin.z(0), initial_params).expectation()\n",
    "e = time.time()\n",
    "print(\"Elapsed time for 30 executions:\", e - s)\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lqgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
